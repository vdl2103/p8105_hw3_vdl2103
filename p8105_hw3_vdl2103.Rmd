---
title: "p8105_hw3_vdl2103"
author: Tory Lynch
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(p8105.datasets)
library(tidyverse)
```

#### Problem 1

##### Load and clean data 
```{r}
#Load data
data("brfss_smart2010")
#Clean data  
brfss_data <- filter(brfss_smart2010, Topic == "Overall Health") %>% 
  janitor::clean_names() %>% 
  mutate(response = factor(response, c("Excellent", "Very good", "Good", "Fair", "Poor")))
```

##### Questions and plots 
```{r}
states_with_7_locations <- brfss_data %>%
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarise(n = sum(n_distinct(geo_location))) %>% 
  filter(n > 6)

knitr::kable(states_with_7_locations, caption = "States with more than 7 locations in 2002")
```

The states with more than 7 locations in 2002 are Connecticut, Florida, Massachusetts, North Carolina, New Jersey and Pennsylvania. 

```{r}
locations_per_state <- brfss_data %>%
  group_by(locationabbr, year) %>% 
  summarise(n = sum(n_distinct(geo_location))) 

plot_locations_per_state <-  ggplot(locations_per_state, aes(x = year, y = n, group = locationabbr, 
                            color = factor(locationabbr))) + geom_point() + geom_line()
```


```{r}
prop_excellent_table <- brfss_data %>% 
  filter(year %in% c(2002, 2006, 2010)) %>% 
  filter(locationabbr == "NY" & response == "Excellent") %>% 
  group_by(year) %>% 
  summarise(n = mean(data_value), sd = sd(data_value))
  
  knitr::kable(prop_excellent_table, caption = "Mean and Standard Deviation of Respondents Reporting 
               Excellent Health in New York in 2002, 2006, 2010")
```

```{r}
five_panel <- brfss_data %>% 
  select(1:3, 7, 9) %>% 
  spread(response, data_value) %>% 
  janitor::clean_names() %>% 
  group_by(year, locationabbr) %>% 
  summarise(excellent_n = mean(excellent), 
            v_good_n = mean(very_good), 
            good_n = mean(good), 
            fair_n = mean(fair), 
            poor_n = mean(poor)) %>% 
gather("response", "data_value", 3:7)

ggplot(five_panel, aes(x = year, y = data_value, color = locationabbr)) + 
        geom_point() + 
        geom_line() + 
        facet_grid(. ~ response)
```


#### Question 2 

##### Import data
```{r}
data("instacart")
dim(instacart)
```

```{r}
n_distinct(instacart$aisle_id)

max_aisles <- instacart %>% 
  group_by(aisle, department_id) %>% 
  count() %>% 
  arrange(desc(n))

print(max_aisles[1:10,])

ggplot(instacart, aes(x = aisle_id, fill = department)) + geom_histogram(position = "dodge", binwidth = 30)
```

```{r}
popular_items_table <- instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  count() %>% 
  group_by(aisle) %>% 
  top_n(n = 1)
```

```{r}
apples_and_coffee_table <- instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(n = mean(order_hour_of_day)) %>% 
  spread(order_dow, n)
```

#### Problem 3 

##### Data import
```{r}
data("ny_noaa")
dim(ny_noaa)
skimr::skim(ny_noaa)
colMeans(is.na(ny_noaa))
```

##### Data cleaning 
```{r}
noaa_data_cleaned <- ny_noaa %>% 
  separate(date, c("y","m", "d")) %>% 
  mutate(prcp_mm = prcp/10) %>%  #put precip into mm 
  mutate(tmax_c = as.numeric(tmax)/10) %>% 
  mutate(tmin_c = as.numeric(tmin)/10)

ggplot(noaa_data_cleaned, aes(x = snow)) + geom_histogram(binwidth = 30) + xlim(c(0,1000))
```

```{r}
max_temp_jan_july <- noaa_data_cleaned %>% 
  filter(m %in% c("01","07")) %>% 
  select(1:3, 11) %>% 
  group_by(id, y, m) %>% 
  summarise(n = mean(tmax_c)) 
  
ggplot(max_temp_jan_july, aes(x = y, y = n, color = id)) + 
        geom_point() + 
        geom_line() + 
        facet_grid(. ~ m) + 
        theme(legend.position = "none")
  
```


